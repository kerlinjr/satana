{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.append('../src/utils')\n",
    "\n",
    "from ac_object_etl_functions import *\n",
    "#%load_ext memray\n",
    "# Load in the data labels\n",
    "params = {}\n",
    "#params['category_index_column'] = \"present1hot\"\n",
    "params['category_labels'] = ['No', 'Yes']\n",
    "params['images_folder'] = '../data/images/ac_150_images'\n",
    "params[\"data_labels_path\"] = '../data/labels/ac_150_labels_jess_notes.csv'\n",
    "params[\"annotation_path\"] = '../data/labels/Export v2 project - AC Unit Evaluation Test - 7_3_2024.ndjson'\n",
    "params[\"iou_threshold\"] = 1.0/3\n",
    "params[\"annotators_per_image\"] = 5\n",
    "# params['kernal'] = np.ones((12,12), np.uint8)\n",
    "# params['hsv_range'] = [[8, 120, 200], [12, 255, 255]]\n",
    "# params['min_ratio'] = 2\n",
    "params['dataset_version'] = 'v4'\n",
    "params['rerun_ds_generation'] = True\n",
    "\n",
    "prime_labels = load_ac_data_spreadsheet(params)\n",
    "prime_labels = prime_labels.rename(columns = {'row_number ': 'row_number'})\n",
    "label_set = pd.read_json(params[\"annotation_path\"], lines=True)\n",
    "df = extract_label_data(label_set)\n",
    "#join prime_labels row_number to df with image_id\n",
    "df = pd.merge(df, prime_labels[['image_id','row_number']], on = 'image_id', how = 'inner')\n",
    "df = df.rename(columns = {'row_number': 'image_orig_idx'})\n",
    "\n",
    "#remove intersecting bounding box (specific to ../data/images/ac_150)\n",
    "df = df[df['feature_id'] != 'clxgcq78i00hx3b6qit987ryb']\n",
    "\n",
    "matched_sets = generate_matched_sets(df, params[\"iou_threshold\"], params[\"annotators_per_image\"])"
   ],
   "id": "be9d860afa2148a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#May be greater than 100 you have intersecting sets, need to resolve with filter\n",
    "agree_bin = matched_sets.groupby(['name','percent_agreement']).size().rename('count').reset_index().join(matched_sets.groupby(['name']).size().rename('total'), on = 'name')\n",
    "agree_bin['percent_total'] = agree_bin['count']/agree_bin['total']*100\n",
    "print(agree_bin)\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "filt_connected_sets = matched_sets[matched_sets['num_agree_in_set'] >= 3]\n",
   "id": "fa41f88ec537464d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "min_matches_per_image = 3\n",
    "\n",
    "worker_has_polygon = df[['image_id', 'name', 'worker']].drop_duplicates()\n",
    "worker_has_polygon['ind_worker_label'] = int(1)\n",
    "worker_has_polygon['cross_join'] = 1\n",
    "\n",
    "#labeler_df = connected_sets.copy(deep = True)\n",
    "labeler_df = matched_sets[matched_sets['num_agree_in_set'] >= min_matches_per_image]\n",
    "labeler_df = labeler_df[['image_id','name']].drop_duplicates()\n",
    "comp_to_prime = labeler_df.reset_index(drop=False)\n",
    "comp_to_prime['labeler_consensus'] = 1\n",
    "ac_comp = comp_to_prime[comp_to_prime['name'] == 'AC Unit']\n",
    "ac_comp = pd.merge(ac_comp, prime_labels[['image_id','present1hot']], on = ['image_id'], how = 'outer').rename(columns = {'present1hot': 'prime_label'})\n",
    "ac_comp['name'] = 'AC Unit'\n",
    "#ac_comp['averaged_polygons'] = ac_comp['averaged_polygons'].fillna(0)\n",
    "leak_comp = comp_to_prime[comp_to_prime['name'] == 'AC leaking']\n",
    "leak_comp = pd.merge(leak_comp, prime_labels[['image_id','leaking1hot']], on = ['image_id'], how = 'outer').rename(columns = {'leaking1hot': 'prime_label'})\n",
    "leak_comp['name'] = 'AC leaking'\n",
    "#leak_comp['averaged_polygons'] = leak_comp['averaged_polygons'].fillna(0)\n",
    "comp_to_prime = pd.concat([ac_comp,leak_comp],axis=0,ignore_index=True)\n",
    "comp_to_prime['labeler_consensus'] = comp_to_prime['labeler_consensus'].fillna(0)\n",
    "\n",
    "comp_to_prime['match'] = (comp_to_prime['prime_label'] == comp_to_prime['labeler_consensus']).astype(int)\n",
    "\n",
    "comp_to_prime['hit'] = ((comp_to_prime['prime_label'] == 1) & (comp_to_prime['labeler_consensus'] == 1)).astype(int)\n",
    "comp_to_prime['correct_rejection'] = ((comp_to_prime['prime_label'] == 0) & (comp_to_prime['labeler_consensus'] == 0)).astype(int)\n",
    "comp_to_prime['false_alarm'] = ((comp_to_prime['prime_label'] == 0) & (comp_to_prime['labeler_consensus'] == 1)).astype(int)\n",
    "comp_to_prime['miss'] = ((comp_to_prime['prime_label'] == 1) & (comp_to_prime['labeler_consensus'] == 0)).astype(int)\n",
    "comp_to_prime['cross_join'] = 1\n",
    "\n",
    "worker_comp_to_prime = pd.merge(comp_to_prime, worker_has_polygon[['worker','cross_join']].drop_duplicates(), on = ['cross_join'], how = 'outer').fillna(0)\n",
    "comp_to_prime = comp_to_prime.drop(columns = ['cross_join']).fillna(0)\n",
    "worker_comp_to_prime = worker_comp_to_prime.drop(columns = ['cross_join'])\n",
    "worker_has_polygon = worker_has_polygon.drop(columns = ['cross_join'])\n",
    "\n",
    "worker_comp_to_prime = pd.merge(worker_comp_to_prime, worker_has_polygon, on = ['image_id','name','worker'], how = 'outer').fillna(0)"
   ],
   "id": "f255eb4f7a0d7820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "confusion_matrix = pd.crosstab(comp_to_prime.loc[(comp_to_prime['name'] == 'AC Unit'),'prime_label'], comp_to_prime['labeler_consensus'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "print(confusion_matrix)"
   ],
   "id": "d5fd7737677d7593",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "confusion_matrix = pd.crosstab(comp_to_prime.loc[(comp_to_prime['name'] == 'AC leaking'),'prime_label'], comp_to_prime['labeler_consensus'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "print(confusion_matrix)"
   ],
   "id": "b3bce92d6b772ae1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for worker in worker_comp_to_prime['worker'].unique(): \n",
    "#     comp_filt = ((worker_comp_to_prime['name'] == 'AC Unit') & (worker_comp_to_prime['worker'] == worker))\n",
    "#     confusion_matrix = pd.crosstab(worker_comp_to_prime.loc[comp_filt,'prime_label'], worker_comp_to_prime.loc[(worker_comp_to_prime['worker'] == worker),'ind_worker_label'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "# \n",
    "#     print(worker + ': ')\n",
    "#     print(confusion_matrix)\n",
    "#     print(' ')"
   ],
   "id": "7fc57259e0fa5dcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for worker in worker_comp_to_prime['worker'].unique(): \n",
    "#     comp_filt = ((worker_comp_to_prime['name'] == 'AC leaking') & (worker_comp_to_prime['worker'] == worker))\n",
    "#     confusion_matrix = pd.crosstab(worker_comp_to_prime.loc[comp_filt,'prime_label'], worker_comp_to_prime.loc[(worker_comp_to_prime['worker'] == worker),'ind_worker_label'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "# \n",
    "#     print(worker + ': ')\n",
    "#     print(confusion_matrix)\n",
    "#     print(' ')"
   ],
   "id": "fe66dfc6d2c9283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_f1_score(confusion_matrix):\n",
    "    # Calculate precision and recall from the confusion matrix\n",
    "    TruePositives = confusion_matrix[1][1]\n",
    "    FalsePositives = confusion_matrix[0][1]\n",
    "    FalseNegatives = confusion_matrix[1][0]\n",
    "\n",
    "    precision = TruePositives / (TruePositives + FalsePositives)\n",
    "    recall = TruePositives / (TruePositives + FalseNegatives)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "confusion_matrix = pd.crosstab(comp_to_prime.loc[(comp_to_prime['name'] == 'AC Unit'),'prime_label'], comp_to_prime['labeler_consensus'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "f1_score_leaking = calculate_f1_score(confusion_matrix)\n",
    "print(confusion_matrix)\n",
    "print('AC Unit: ' + str(f1_score_leaking))\n",
    "\n",
    "# Assuming 'confusion_matrix' is the confusion matrix you have calculated\n",
    "confusion_matrix = pd.crosstab(comp_to_prime.loc[(comp_to_prime['name'] == 'AC leaking'),'prime_label'], comp_to_prime['labeler_consensus'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "f1_score_leaking = calculate_f1_score(confusion_matrix)\n",
    "print(confusion_matrix)\n",
    "print('AC leaking: ' + str(f1_score_leaking))\n",
    "\n"
   ],
   "id": "ea711c3a89ce5bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "worker_has_polygon = df[['image_id', 'name', 'worker']].drop_duplicates()\n",
    "worker_has_polygon['ind_worker_label'] = int(1)\n",
    "worker_has_polygon['cross_join'] = 1\n",
    "\n",
    "labeler_df = matched_sets.copy(deep = True)\n",
    "comp_to_prime = labeler_df.reset_index(drop=False)\n",
    "comp_to_prime['labeler_consensus'] = 1\n",
    "ac_comp = comp_to_prime[comp_to_prime['name'] == 'AC Unit']\n",
    "ac_comp = pd.merge(ac_comp, prime_labels[['image_id','present1hot']], on = ['image_id'], how = 'outer').rename(columns = {'present1hot': 'prime_label'}).fillna(0)\n",
    "ac_comp['name'] = 'AC Unit'\n",
    "#ac_comp['averaged_polygons'] = ac_comp['averaged_polygons'].fillna(0)\n",
    "leak_comp = comp_to_prime[comp_to_prime['name'] == 'AC leaking']\n",
    "leak_comp = pd.merge(leak_comp, prime_labels[['image_id','leaking1hot']], on = ['image_id'], how = 'outer').rename(columns = {'leaking1hot': 'prime_label'}).fillna(0)\n",
    "leak_comp['name'] = 'AC leaking'\n",
    "#leak_comp['averaged_polygons'] = leak_comp['averaged_polygons'].fillna(0)\n",
    "comp_to_prime = pd.concat([ac_comp,leak_comp],axis=0,ignore_index=True)\n",
    "comp_to_prime['labeler_consensus'] = comp_to_prime['labeler_consensus'].fillna(0)\n",
    "\n",
    "comp_to_prime['match'] = (comp_to_prime['prime_label'] == comp_to_prime['labeler_consensus']).astype(int)\n",
    "\n",
    "comp_to_prime['hit'] = ((comp_to_prime['prime_label'] == 1) & (comp_to_prime['labeler_consensus'] == 1)).astype(int)\n",
    "comp_to_prime['correct_rejection'] = ((comp_to_prime['prime_label'] == 0) & (comp_to_prime['labeler_consensus'] == 0)).astype(int)\n",
    "comp_to_prime['false_alarm'] = ((comp_to_prime['prime_label'] == 0) & (comp_to_prime['labeler_consensus'] == 1)).astype(int)\n",
    "comp_to_prime['miss'] = ((comp_to_prime['prime_label'] == 1) & (comp_to_prime['labeler_consensus'] == 0)).astype(int)\n",
    "comp_to_prime['cross_join'] = 1"
   ],
   "id": "491ceee88f118664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for agreement in comp_to_prime['percent_agreement'].unique(): \n",
    "    comp_filt = ((comp_to_prime['name'] == 'AC Unit') & (comp_to_prime['percent_agreement'] == agreement))\n",
    "    confusion_matrix = pd.crosstab(comp_to_prime.loc[comp_filt,'prime_label'], comp_to_prime.loc[(comp_to_prime['percent_agreement'] == agreement),'labeler_consensus'], rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "    print(str(agreement) + ': ')\n",
    "    print(confusion_matrix)\n",
    "    print(' ')"
   ],
   "id": "510688e3ffa4a330",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "accuracy_by_agreement = comp_to_prime.groupby(['name','percent_agreement'])['match'].mean().rename('percent_accuracy')*100",
   "id": "4152a41df6522958",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'accuracy_by_agreement' is your DataFrame\n",
    "accuracy_by_agreement = accuracy_by_agreement.reset_index()\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_table = accuracy_by_agreement.pivot(index='percent_agreement', columns='name', values='percent_accuracy')\n",
    "\n",
    "# Plot the data\n",
    "pivot_table.plot(kind='bar', stacked=False)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('% Labelers Match on Object Detection')\n",
    "plt.ylabel('% Accuracy')\n",
    "plt.title('Accuracy by % Labelers Match on Object Detection')\n",
    "legend = plt.legend(title='Object Type', loc='lower left')\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "id": "353a7d0ad1385bf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d58c90cea8040a8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7686c897d597957e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
