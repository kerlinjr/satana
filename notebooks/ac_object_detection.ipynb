{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T17:54:01.365484Z",
     "start_time": "2024-08-13T17:54:01.360610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/utils')\n",
    "\n",
    "from ac_object_detection_functions import *"
   ],
   "id": "b75f7dc384de4e4d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Load in the original model\n",
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotObjectDetection\n",
    "device = torch.device(\"mps\")\n",
    "model_id = \"IDEA-Research/grounding-dino-tiny\"\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "model = AutoModelForZeroShotObjectDetection.from_pretrained(model_id, ignore_mismatched_sizes=True).to(device)\n"
   ],
   "id": "7b68d45b6f700604",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "# Load API key and project ID from a configuration file\n",
    "with open('../config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    organization= config['OPENAI_ORG_ID'],\n",
    "    project=config['OPENAI_PROJECT_ID'],\n",
    "    api_key=config['OPENAI_API_KEY']\n",
    ")\n"
   ],
   "id": "361a0b33512cc632",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "with_hvac = [0, 1, 3, 6, 8, 9, 10, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 45, 46, 47, 50, 51, 53, 56, 57, 59, 60, 61, 65, 66, 68, 70, 71, 72, 75, 76, 77, 79, 81, 83, 85, 86, 87, 88, 91, 93, 94, 95, 96, 97, 98, 99, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 115, 118, 119, 121, 122, 123, 125, 126, 128, 129, 130, 132, 133, 134, 135, 137, 138, 140, 142, 143, 144, 145, 147, 149]",
   "id": "43fdfe2557a00f73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "with_leak = [0, 6, 8, 10, 12, 13, 18, 25, 29, 39, 42, 43, 45, 47, 51, 56, 61, 65, 66, 68, 70, 71, 72, 75, 76, 77, 79, 83, 87, 93, 98, 110, 111, 114, 121, 125, 128, 130, 143, 147, 149]\n",
   "id": "9bb2fec2dbf7c360",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "category_options = ['AC Unit', 'AC leaking']\n",
    "\n",
    "params = {}\n",
    "params['manual_prompt'] = False\n",
    "input_prompt = '\"Tight box around HVAC on roof.\"'\n",
    "params['rerun_zero_shot'] = True\n",
    "params['dataset_version'] = 'v4'\n",
    "params['seed'] = 42\n",
    "params['category_idx'] = 1\n",
    "params['display_image'] = False\n",
    "params['max_boxes'] = 900 #has to be 900 for the model to work\n",
    "params['area_threshold'] = 0.20\n",
    "params['score_threshold'] = 0.1\n",
    "params['overlap_threshold'] = 0.5\n",
    "params['skinny_threshold'] = 0.15\n",
    "params['text_version'] = 'v4'\n",
    "params['model_version'] = 'v3'\n",
    "params['partial_run'] = True\n",
    "params['partial_run_subset_count'] = 10\n",
    "params['iou_threshold'] = 0.33\n",
    "params[\"LLM_try_total\"] = 3\n",
    "model.config.num_queries = params['max_boxes']\n",
    "\n",
    "ds = datasets.load_from_disk(\"../data/models/ac_model/ac_object_\" + params['dataset_version'] + \".hf\")\n",
    "#set seed for random\n",
    "random.seed(params['seed'])\n",
    "\n",
    "train_idx_image = random.sample(range(0,len(ds)), int(len(ds)*0.8))\n",
    "test_idx_image = [x for x in range(0,len(ds)) if x not in train_idx_image]\n",
    "params['category'] = category_options[params['category_idx']]\n",
    "if params['partial_run'] == True:\n",
    "    if params['category_idx'] == 0:\n",
    "        zero_shot_set = random.sample([x for x in train_idx_image if x in with_hvac], params['partial_run_subset_count'])\n",
    "    elif params['category_idx'] == 1:\n",
    "        zero_shot_set = random.sample([x for x in train_idx_image if x in with_leak], params['partial_run_subset_count'])\n",
    "else:\n",
    "    zero_shot_set = range(0, len(ds))\n",
    "    \n",
    "\n",
    "category_idx = params['category_idx']\n",
    "print(model_id)\n",
    "\n",
    "\n",
    "#initialization\n",
    "# starter_tries = {'a tiny HVAC (air conditioner) machine that MUST be ON a roof. Make a tight bounding box.': '0.83', 'HVAC on roof.': '0.73', 'A small, off-white or grey HVAC unit on a rooftop, featuring a rectangular shape and a circular fan on top. Use a precise bounding box.' : '0.69','A small rectangular HVAC unit with a circular fan on top, located on a rooftop. Ensure a tight and accurate bounding box.': '0.77'}\n",
    "\n",
    "starter_tries = {'HVAC on a roof including a smear or leak': '?'}\n",
    "\n",
    "\n",
    "prompt_results = starter_tries\n",
    "\n",
    "try_count = len(prompt_results.keys())\n",
    "\n",
    "\n",
    "if params['manual_prompt'] == True:\n",
    "    try_count = params[\"LLM_try_total\"]-1\n",
    "\n",
    "while try_count < params[\"LLM_try_total\"]:\n",
    "\n",
    "\n",
    "    if category_idx == 0:\n",
    "        params[\"prompt_seed\"] = (\"You are trying to get GroundingDino to find and put bounding boxes on all HVAC systems (typically air conditioners) on a roof based on aerial imagery. GroundingDinop expects a prompt to be a concise description of the object, but it wasn't trained much on aerial imagery so it may need help in describing the object. I have no idea if grammar matters. The image is of a building's rooftop. The HVAC units usually take up less than 5% of the image and look like small, rectangular boxes with one or more circular fan(s) on top. The unit is typically white or grey. Sometimes the units will have pipes or vents visibly connected to them, but not always. GroundingDino tends to have looser bounding boxes, but we want tight bounding boxes. You could think of other synonyms to help.\")\n",
    "    elif category_idx == 1:\n",
    "        params[\"prompt_seed\"] = (\"You are trying to get GroundingDino to find and put bounding boxes on all leaking HVAC on roof systems as seen on a roof based on aerial imagery. You need it to draw around both the system itself and the discoloration caused by the leak. The leaks could be described as looking like smears, stains, traces or sediment flowing down the roof from the HVAC system.\")     \n",
    "    \n",
    "    params[\"LLM instructions\"] = (\"You are helping with an experiment to find the best prompt for a generalized multimodal modal to make it specialized at finding an object. Your job is to generate prompts you believe will be successful based on the prompt seed information and a history of how well each previous prompt performed. The goal is to test lots of different options to find the best one, learning from the previous prompts that were most successful. You have been given a total of \" + str(params[\"LLM_try_total\"]) + \" tries to generate prompts. You have already used \" + str(try_count) + \" tries. The results of your previous tries are contained in a dictionary with the text prompt as a key and the corresponding f1 score. The higher the score, the better the prompt, with a maximum score of 1.00. The prompt seed information is: \" + params[\"prompt_seed\"] + \"The previous trial results are: \" + str(prompt_results) + \". Please generate a new prompt based on this information. Your output should be a single string with no commentary. Try to make the shortest possible prompt while maximizing the f1 score. Use fewer than 10 words, ideally 2 to 5. NEVER do the exact same prompt twice. Review the previous prompts to make sure this doesn't happen.\")  \n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": params[\"LLM instructions\"]\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-4o-mini\",\n",
    "    )\n",
    "    if params['manual_prompt'] == True:\n",
    "        response = input_prompt\n",
    "    else:\n",
    "        response = chat_completion.choices[0].message.content\n",
    "    print('Try ' + str(try_count) + ' with prompt: ' + response)\n",
    "    \n",
    "    prompt_results[response] = ''\n",
    "    params['text_idx'] = len(prompt_results.keys()) - 1\n",
    "    params['text'] = response\n",
    "    text = params['text'] \n",
    "    if params['rerun_zero_shot'] == True:\n",
    "        zero_shot_df = pd.DataFrame()\n",
    "        for image_dict_idx in zero_shot_set:    \n",
    "            \n",
    "            human_labels = ds[image_dict_idx]['objects']\n",
    "            image = ds[image_dict_idx]['image']\n",
    "            with torch.no_grad():\n",
    "                inputs = processor(images=image, text=text, return_tensors=\"pt\").to(device)\n",
    "            \n",
    "                outputs = model(**inputs,output_hidden_states=True)\n",
    "                results = processor.post_process_grounded_object_detection(\n",
    "                    outputs,\n",
    "                    inputs.input_ids,\n",
    "                    box_threshold=0.00,\n",
    "                    text_threshold=0.00,\n",
    "                    target_sizes=[image.size[::-1]],\n",
    "            \n",
    "                )\n",
    "        \n",
    "            qualified_box_idx = filter_model_bbox_outputs(results, outputs, image, params)\n",
    "            if len(qualified_box_idx) == 0:\n",
    "                qualified_box_idx = [0]\n",
    "            filt_outputs = FilteredOutputs()\n",
    "            \n",
    "            for output_items in ['pred_boxes', 'last_hidden_state']:\n",
    "                # filter the tensor's 2nd dimension by qualified_box_idx\n",
    "                setattr(filt_outputs, output_items, outputs[output_items][:, qualified_box_idx, :])\n",
    "        \n",
    "            boxes = results[0]['boxes'][qualified_box_idx]\n",
    "            if len(boxes) == 0:\n",
    "                scores = [0]\n",
    "            else:\n",
    "                scores = results[0]['scores'].cpu().numpy()[qualified_box_idx]\n",
    "            mdf = pd.DataFrame(columns = ['model_boxes'])\n",
    "            mdf['model_boxes'] = [[int(y) for y in x] for x in boxes.tolist()]\n",
    "            mdf['scores'] = scores\n",
    "            mdf['model_idx'] = mdf.index\n",
    "            mdf['image_idx'] = image_dict_idx\n",
    "            mdf['tmp_key'] = 1\n",
    "            \n",
    "            \n",
    "            hdf = human_labels_to_df(human_labels, category_idx)\n",
    "            hdf['human_idx'] = hdf.index\n",
    "            hdf['tmp_key'] = 1\n",
    "            annot_df = pd.merge(hdf,mdf, on='tmp_key')\n",
    "            annot_df['iou'] = annot_df.apply(lambda row: calculate_iou_not_polygon(row['human_boxes'], row['model_boxes']), axis=1)\n",
    "            best_match_df = annot_df.sort_values('iou', ascending=False).drop_duplicates(['model_boxes']).sort_values('model_idx')\n",
    "            \n",
    "            best_match_df['last_hidden_state'] = filt_outputs.last_hidden_state.cpu().tolist()[0]\n",
    "            best_match_df['image_idx'] = image_dict_idx\n",
    "            # logits = filt_outputs.logits.cpu().numpy()[0]\n",
    "            # logits = list(logits[:, (logits != float('-inf')).any(axis=0)])\n",
    "            # best_match_df['logits'] = logits\n",
    "            \n",
    "            zero_shot_df = pd.concat([zero_shot_df,best_match_df], ignore_index=True)\n",
    "            print('Image index: ' +str(image_dict_idx) + ' ' + 'for category_idx ' + str(category_idx) + ' processed with text index: ' + str(params['text_idx']) + ' and model version: ' + params['model_version'])\n",
    "        if params['partial_run'] == True:\n",
    "            filename = \"../data/models/ac_model/partial/zero_shot_df_\" + params[\"dataset_version\"] + '_t' + str(params[\"text_idx\"]) + \"_\" + params[\"model_version\"] + \"_partial.pkl\"\n",
    "        else:\n",
    "            filename = \"../data/models/ac_model/zero_shot_df_\" + params[\"dataset_version\"] + '_t' + str(params[\"text_idx\"]) + \"_\" + params[\"model_version\"] + \".pkl\"\n",
    "        if params['manual_prompt'] == False:\n",
    "            zero_shot_df.to_pickle(filename)\n",
    "    else:\n",
    "        #load zero shot df from pkl\n",
    "        filename = \"../data/models/ac_model/zero_shot_df_\" + params[\"dataset_version\"] + '_t' + str(params[\"text_idx\"]) + \"_\" + params[\"model_version\"] + \".pkl\"\n",
    "        zero_shot_df = pd.read_pickle(filename)\n",
    "    \n",
    "    \n",
    "    df = zero_shot_df.copy(deep=True)\n",
    "    df['matched'] = (df['iou'] > params['iou_threshold']).astype(int)\n",
    "    y_actual = df['matched']\n",
    "    y_score = df['scores']\n",
    "    zero_shot_score = f1_scoring(y_actual, y_score)\n",
    "    print(zero_shot_score)\n",
    "    prompt_results[text] = str(zero_shot_score)\n",
    "    try_count = len(prompt_results.keys())"
   ],
   "id": "cf9e72023a7eb853",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#save the dictionary prompt_results to disk\n",
    "import pickle\n",
    "filename = \"../data/models/ac_model/prompt_results_\" + params[\"dataset_version\"] + \"_\" + params[\"model_version\"] + \".pkl\"\n",
    "with open(filename , 'wb') as f:\n",
    "    pickle.dump(prompt_results, f)\n"
   ],
   "id": "b6103a64950748fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompt_results",
   "id": "9fe7a69bba925d98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_actual, y_score)\n",
    "J = tpr - fpr\n",
    "# Find the index of the threshold with the greatest Youden's J statistic\n",
    "ix = np.argmax(J)\n",
    "# Find the optimal threshold\n",
    "optimal_threshold = thresholds[ix]\n",
    "y_pred_binary = (y_score > optimal_threshold).astype(int)\n",
    "# print(accuracy_score(y_actual, y_pred_binary))\n",
    "# print(classification_report(y_actual, y_pred_binary))\n",
    "# print(confusion_matrix(y_actual, y_pred_binary))\n",
    "# print(auc(fpr, tpr))\n",
    "# #print f1 score\n",
    "\n",
    "\n",
    " \n",
    "print(f1_score(y_actual, y_pred_binary))\n",
    "y_pred_baseline = y_pred_binary+1 >= 1\n",
    "print(f1_score(y_actual, y_pred_baseline))"
   ],
   "id": "a15fd4e8333f7976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "ss = test_train_split( test_size=0.2, random_state=42)\n",
    "train_index, test_index = ss.split(X, y_iou)\n",
    "for train_index, test_index in ss.split(X, y_iou):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_iou[train_index], y_iou[test_index]"
   ],
   "id": "722e1742a93e9be2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run linear regression to predict the matched column continuous based on the last_hidden_state_diff\n",
    "df = zero_shot_df.copy(deep=True)\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "#X = np.array(train_df['top_states'].tolist())\n",
    "#X = np.array(train_df['last_hidden_state'].tolist())\n",
    "\n",
    "X = np.array(df['last_hidden_state'].tolist())\n",
    "#X = np.array(df['scores'].tolist())\n",
    "#add an intercept\n",
    "X = np.concatenate([X, np.ones((X.shape[0], 1))], axis=1)\n",
    "\n",
    "\n",
    "y_iou = np.array(df['iou'])\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "train_image_idx = random.sample(range(0,len(ds)), int(len(ds)*0.8))\n",
    "test_image_idx = [x for x in range(0,len(ds)) if x not in train_image_idx]\n",
    "\n",
    "train_idx = np.array(df[df['image_idx'].isin(train_image_idx)].index) \n",
    "test_idx = np.array(df[df['image_idx'].isin(test_image_idx)].index)\n",
    "\n",
    "\n",
    "# test_idx = list(set(np.concatenate([test_idx,np.array([429, 430, 431, 432, 433, 434])])))\n",
    "# train_idx = np.array([x for x in indicies if x not in test_idx])\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_iou_train = y_iou[train_idx]\n",
    "y_iou_test = y_iou[test_idx]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['matched'] = (df['iou'] > 0.33).astype(int)\n",
    "y_matched = np.array(df['matched'])\n",
    "y_matched_train = y_matched[train_idx]\n",
    "y_matched_test = y_matched[test_idx]\n",
    "\n",
    "y_orig_score = np.array(df['scores'])\n",
    "y_orig_score_train = y_orig_score[train_idx]\n",
    "y_orig_score_test = y_orig_score[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "#get coefficients for the lasso model to iou\n",
    "clf = Lasso(alpha=0.001)\n",
    "clf.fit(X_train, y_iou_train)\n",
    "y_pred_iou = clf.predict(X_test)\n",
    "#find and report coefficients\n",
    "coefficients = clf.coef_\n",
    "iou_pred_error = root_mean_squared_error(y_iou_test, y_pred_iou)\n",
    "print(\"iou prediction error: \" + str(iou_pred_error))\n",
    "print(\"Number of non-zero coefficients: \", len(coefficients[coefficients != 0]))\n",
    "plt.plot(coefficients)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "fpr, tpr, thresholds = roc_curve(y_matched_test, y_pred_iou)\n",
    "fpr_o, tpr_o, thresholds_o = roc_curve(y_matched_test, y_orig_score_test)\n",
    "# beta = 1\n",
    "# def find_optimal_threshold(y_true, y_scores,beta):\n",
    "#     # Calculate the ROC curve points\n",
    "#     fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "# \n",
    "#     # Calculate the F1 score for each threshold\n",
    "#     f1_scores = [fbeta_score(y_true, y_scores > t, beta = beta) for t in thresholds]\n",
    "# \n",
    "#     # Get the optimal threshold\n",
    "#     optimal_idx = np.argmax(f1_scores)\n",
    "#     optimal_threshold = thresholds[optimal_idx]\n",
    "# \n",
    "#     return optimal_threshold\n",
    "# optimal_threshold = find_optimal_threshold(y_matched_test, y_pred_iou,beta)\n",
    "# optimal_threshold_o = find_optimal_threshold(y_matched_test, y_orig_score_test,beta)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "roc_auc_o = auc(fpr_o, tpr_o)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "\n",
    "plt.plot(fpr_o, tpr_o, color='darkblue', lw=lw, label='Before Tuning (area = %0.2f)' % roc_auc_o)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='After Tuning with Grande data (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('HVAC Detection Performance with GroundingDino')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "#Compute the Youden's J statistic\n",
    "J = tpr - fpr\n",
    "J_o = tpr_o - fpr_o\n",
    "\n",
    "# # Find the index of the threshold with the greatest Youden's J statistic\n",
    "ix = np.argmax(J)\n",
    "ix_o = np.argmax(J_o)\n",
    "\n",
    "# Find the optimal threshold\n",
    "optimal_threshold = thresholds[ix]\n",
    "optimal_threshold_o = thresholds[ix]\n",
    "print('Grande Optimal Threshold: ', optimal_threshold)\n",
    "print('Zero Shot Optimal Threshold: ', optimal_threshold_o)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Grande Model\")\n",
    "y_pred_binary = (y_pred_iou > optimal_threshold).astype(int)\n",
    "print(accuracy_score(y_matched_test, y_pred_binary))\n",
    "print(classification_report(y_matched_test, y_pred_binary))\n",
    "print(confusion_matrix(y_matched_test, y_pred_binary))\n",
    "print(f1_scoring(y_matched_test, y_pred_iou))\n",
    "\n",
    "print(\"Zero Shot Model\")\n",
    "y_orig_score_binary = (y_orig_score_test > optimal_threshold_o).astype(int)\n",
    "print(accuracy_score(y_matched_test, y_orig_score_binary ))\n",
    "print(classification_report(y_matched_test, y_orig_score_binary ))\n",
    "print(confusion_matrix(y_matched_test, y_orig_score_binary ))\n",
    "print(f1_scoring(y_matched_test, y_orig_score_test))"
   ],
   "id": "ec5d015a6ef1811d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "def spot_check_annotations(full_train, image_idx = 320, min_agreement = 80, zoom = False):\n",
    "    patch_df = (full_train[(full_train['image_id'] == full_train['image_id'].iloc[image_idx])\n",
    "                          & (full_train['percent_agreement'] >= min_agreement)])\n",
    "    category = np.array(patch_df['name'])\n",
    "    mask_geometry = patch_df['mask_geometry'].iloc[0]\n",
    "    category_polygons = patch_df['averaged_polygons']\n",
    "    image_path = patch_df['image_path'].iloc[0]\n",
    "    display_image_with_mask(image_path, mask_geometry, category_polygons, category, zoom = zoom)\n",
    "\n",
    "def convert_polygon_to_bbox(polygon):\n",
    "    minx, miny, maxx, maxy = polygon.bounds\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "    return minx, miny, width, height\n",
    "\n",
    "\n",
    "def display_image_with_mask(image_path, mask_geometry, category_polygons, category, zoom=False):\n",
    "    # Load the image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "\n",
    "    if isinstance(category_polygons, Polygon):\n",
    "        category_polygons= [category_polygons]\n",
    "\n",
    "\n",
    "    if not zoom: # Display the mask\n",
    "        x, y, width, height = convert_polygon_to_bbox(mask_geometry)\n",
    "        patch = patches.Rectangle((x,y),width,height, edgecolor='green', facecolor='None',linewidth=2)\n",
    "        ax.add_patch(patch)\n",
    "    \n",
    "    # Display the averaged polygons\n",
    "    for cnt,polygon in enumerate(category_polygons):\n",
    "        x, y, width, height = convert_polygon_to_bbox(polygon)\n",
    "        if category[cnt] == 'AC Unit':\n",
    "            color = 'green'\n",
    "        elif category[cnt] == 'AC leaking':\n",
    "            color = 'red'\n",
    "        else:\n",
    "            ValueError('Category not recognized')\n",
    "            \n",
    "        patch = patches.Rectangle((x,y),width,height, edgecolor=color, facecolor='None',linewidth=2)\n",
    "        ax.add_patch(patch)\n",
    "    \n",
    "    if zoom:\n",
    "        # Set the limits of the plot to the extent of the mask\n",
    "        minx, miny, maxx, maxy = mask_geometry.bounds\n",
    "        ax.set_xlim(minx, maxx)\n",
    "        ax.set_ylim(miny, maxy)\n",
    "        ax.grid(False)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "df = zero_shot_df.copy(deep=True)\n",
    "df = df.iloc[test_idx,:]\n",
    "df['new_scores'] = y_pred_iou\n",
    "df['new_matched'] = (df['new_scores'] > optimal_threshold).astype(int)\n",
    "df['orig_scores'] = y_orig_score_test\n",
    "df['orig_matched'] = (df['orig_scores'] > optimal_threshold_o).astype(int)\n",
    "\n",
    "\n",
    "image_idxs = [test_idx_image[0]]\n",
    "\n",
    "\n",
    "for image_idx in image_idxs:\n",
    "    patch_df = df[(df[\"image_idx\"] == image_idx)].reset_index(drop=True)\n",
    "    \n",
    "    image = ds[image_idx]['image']\n",
    "\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    new_patch = patch_df[patch_df['new_matched'] == 1]\n",
    "    for idx in range(len(new_patch)):\n",
    "        x1, y1, x2, y2 = new_patch['model_boxes'].iloc[idx]\n",
    "        patch = patches.Rectangle((x1,y1),x2-x1,y2-y1, edgecolor='yellow', facecolor='None',linewidth=4)\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "        # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    for idx in range(len(patch_df)):\n",
    "        x1, y1, x2, y2 = patch_df['human_boxes'].iloc[idx]\n",
    "        patch = patches.Rectangle((x1,y1),x2-x1,y2-y1, edgecolor='yellow', facecolor='None',linewidth=4)\n",
    "        ax.add_patch(patch)\n",
    "\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    \n",
    "    old_patch = patch_df[patch_df['orig_matched'] == 1]\n",
    "    for idx in range(len(old_patch)):\n",
    "        x1, y1, x2, y2 = old_patch['model_boxes'].iloc[idx]\n",
    "        patch2 = patches.Rectangle((x1,y1),x2-x1,y2-y1, edgecolor='yellow', facecolor='None',linewidth=4)\n",
    "        ax.add_patch(patch2)\n",
    "    \n",
    "    ax.imshow(image)"
   ],
   "id": "bcc0d053b3523090",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
